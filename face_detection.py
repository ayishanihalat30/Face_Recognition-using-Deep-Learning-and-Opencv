# -*- coding: utf-8 -*-
"""Face_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VT-7vbaRNEI0PGmPJvFnbztipKMSvzWm
"""

from glob import glob

from glob import glob
path='/content/drive/MyDrive/dataset/pictures'
image=glob(path+'/*')
image

amritha_list=list(glob(path+'/amritha/*'))
aleena_list=list(glob(path+'/aleena/*'))
ayisha_list=list(glob(path+'/ayisha/*'))
jincy_list=list(glob(path+'/jincy/*'))

len(amritha_list)

len(ayisha_list)

len(aleena_list)

len(jincy_list)

input_map={'amritha':amritha_list,'aleena':aleena_list,'ayisha':ayisha_list,'jincy':jincy_list}

out_map={'amritha':0,'ayisha':1,'aleena':2,'jincy':3}

import cv2
import numpy as np

import os
import numpy as np
import cv2
x=[]
y=[]
#img_arr=[]
for face in input_map:
  path_list=input_map[face]
  for path in path_list:
            img_array=cv2.imread(path)
            img_array_resize=cv2.resize(img_array,(224,224))
            img_array_resized=img_array_resize/255
            img_array_resizeds=img_array_resized.reshape(224,224,3,1)
            x.append(img_array_resizeds)
            y.append(out_map[face])
            x_=np.array(x)
            y_=np.array(y)

len(x_)
x_.shape

y_.shape

from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest=train_test_split(x_,y_,test_size=.2)
len(xtrain)

len(xtrain),len(ytrain)

len(xtest),len(ytest)

from tensorflow.keras.layers import Dense,Flatten,Conv3D,MaxPool3D
from tensorflow.keras import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import SparseCategoricalCrossentropy

model=Sequential()
model.add(Conv3D(filters=10,kernel_size=(2,2,3),input_shape=(224,224,3,1)))
model.add(MaxPool3D(pool_size=(2,2,1)))
model.add(Conv3D(filters=15,kernel_size=(2,2,1),activation='relu'))
model.add(MaxPool3D(pool_size=(2,2,1)))
model.add(Flatten())
model.add(Dense(units=100,activation='relu'))
model.add(Dense(units=5,activation='sigmoid'))

model.summary()

model.compile(loss=SparseCategoricalCrossentropy(),optimizer=Adam(),metrics=['accuracy'])

tr=model.fit(xtrain,ytrain,epochs=5,validation_data=(xtest,ytest))

def plot_learing_curve(tr):
    import matplotlib.pyplot as plt
    
    train_accuracy=tr.history['accuracy']
    val_accuracy=tr.history['val_accuracy']
    epoch=tr.epoch
    loss=tr.history['loss']
    val_loss=tr.history['val_loss']
    
    plt.plot(epoch,train_accuracy,label='traing accuracy')
    plt.plot(epoch,val_accuracy,label='val accuracy')
    
    plt.xlabel('epochs')
    plt.ylabel('accuracy')
    plt.title('accuracy leraning curve')
    plt.legend()
    plt.show()
    
    plt.plot(epoch,loss,label='loss')
    plt.plot(epoch,val_loss,label='val loss')
    
    plt.xlabel('epochs')
    plt.ylabel('loss')
    plt.title('loss leraning curve')
    plt.legend()
    plt.show()

plot_learing_curve(tr)

import cv2
vid=cv2.VideoCapture('video.mp4')

while vid.isOpened():
    r,frame=vid.read()
    if r==True:
        #convert gray scale
        #frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
        cv2.imshow('video',frame)
        cv2.resize(frame,(500,500))
    if cv2.waitKey(1)==ord('c'):
        break

import cv2

from PIL import Image

Image.open('/content/drive/MyDrive/images/new.jpg')



img_arr=cv2.imread('/content/drive/MyDrive/images/new.jpg')
test_set=[]
img_arr_resize=cv2.resize(img_arr,(224,224))
img_arr_resize.shape
import numpy as np
np.max(img_arr_resize)
img_arr_resize=img_arr_resize/255
img_arr_resize=img_arr_resize.reshape(224,224,3,1)
test_set.append(img_arr_resize)
test=np.array(test_set)
test.shape
result=model.predict(test)
np.argmax(result)

from tensorflow.keras.models import load_model

model.save('face.h5')